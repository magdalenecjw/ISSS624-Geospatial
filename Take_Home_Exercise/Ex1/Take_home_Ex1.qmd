---
title: "1: Geospatial Analytics for Public Good"
author: "Magdalene Chan"
date: 2023-11-25
date-modified: "last-modified"
execute: 
  warning: false
  freeze: auto
format:
  html:
    code-fold: true
---

# Objectives

As city-wide urban infrastructures become increasingly digital, datasets from technologies like GPS and RFID on vehicles offer opportunities to track movement patterns over space and time. For instance, smart cards and GPS devices on public buses collect routes and ridership data, containing valuable structure and patterns for understanding human movement and behavior within cities. Despite their potential, the practical use of these extensive location-aware datasets often remains limited to basic tracking and mapping within GIS applications due to the lack of comprehensive spatial and spatio-temporal analysis functions in conventional GIS tools.

Exploratory Spatial Data Analysis (ESDA) holds tremendous potential to address such complex problems. In this study, appropriate Local Indicators of Spatial Association (GLISA) and Emerging Hot Spot Analysis (EHSA) will be applied to undercover the spatial and spatio-temporal mobility patterns of public bus passengers in Singapore.

# Tasks

The following tasks will be undertaken in this exercise:

## Geovisualisation and Analysis

1.  Compute the passenger trips generated by origin at a hexagon level of 250m for the following time periods:
    1.  Weekday morning peak -- 6am to 9am (inclusive)
    2.  Weekday evening peak -- 5pm to 8pm (inclusive)
    3.  Weekend/holiday morning peak -- 11am to 2pm (inclusive)
    4.  Weekend/holiday evening peak -- 4pm to 7pm (inclusive)
2.  Display the geographical distribution of the passenger trips using appropriate geovisualisation methods.
3.  Describe the spatial patterns revealed by the geovisualisation (not more than 200 words per visual).

## Emerging Hot Spot Analysis

With reference to the passenger trips generated by origin at the hexagon level for the four time periods given above:

1.  Perform Mann-Kendall Test by using the spatio-temporal local G~i~\* values,
2.  Prepare EHSA maps of the G~i~\* values of the passenger trips by origin at the hexagon level. The maps should only display the significant (i.e. p-value \< 0.05).
3.  With reference to the EHSA maps and data visualisation prepared, describe the spatial patterns revealed (not more than 250 words per cluster).

# Getting Started

The code chunk below uses `p_load()` of `pacman` package to check if the required packages have been installed on the computer. If they are, the packages will be launched. The following packages will be used:

-   `sf` package is used for importing, managing, and processing geospatial data.
-   `sfdep` package is used to create spatial weights matrix and LISA objects using the sf class to represent spatial data.
-   `tmap` package is used for thematic mapping.
-   `plotly` package is used to create interactive graphs and charts. 
-   `tidyverse` package is used for aspatial data wrangling.
-   `knitr` package is used for dynamic report generation in R. 

```{r}
pacman::p_load(sf, sfdep, tmap, plotly, tidyverse, knitr)
```

# Import Data

The data sets used are:

-   Bus Stop Location (Last updated Jul 2023) from [LTADataMall](https://datamall.lta.gov.sg/content/datamall/en/static-data.html) retrieved on 18 Nov 2023
-   Passenger Volume by Origin Destination Bus Stops for August 2023 from [LTADataMall](https://datamall.lta.gov.sg/content/datamall/en/dynamic-data.html) retrieved on 18 Nov 2023

## Import Geospatial Data: Bus Stop Locations

The code chunk below uses the `st_read()` function of **sf** package to import `BusStop` shapefile into R as a simple feature data frame called `BusStop`. As `BusStop` uses **svy21** projected coordinate system, the `crs` is set to 3414.

```{r}
BusStop <- st_read(dsn = "data/geospatial", 
                layer = "BusStop") %>%
  st_transform(crs=3414)
```

There are a total of 5161 features in the `BusStop` shapefile.

Next, examine the structure of the data frame using the code chunk below.

```{r}
str(BusStop)
```

Based on the data frame structure seen above, `BUS_STOP_N` is listed as a character variable. As this variable will be used as the identifier to link to the aspatial data, it should be transformed to a factor so that R treats it as a grouping variable.

```{r}
# Apply as.factor() to the column
BusStop$BUS_STOP_N <- as.factor(BusStop$BUS_STOP_N)

# Re-examine the structure of the data frame
str(BusStop)
```

Based on the output above, `BUS_STOP_N` is now a factor.

It is good practice to check for duplicating records before continuing further with the data wrangling.

```{r}
duplicate <- BusStop[duplicated(st_geometry(BusStop)) | duplicated(st_geometry(BusStop), 
                                                                   fromLast = TRUE), ]

duplicate
```

As shown above, there are duplicate records of Bus Stop Number 96319. The code chunk below will be used to retain one unique record by taking the first occurrence. 

```{r}
BusStop <- BusStop[!duplicated(st_geometry(BusStop)) | duplicated(st_geometry(BusStop), 
                                                                  fromLast = TRUE), ] %>%
  mutate(BUS_ROOF_N = ifelse(is.na(BUS_ROOF_N), "NIL", BUS_ROOF_N))

# Re-examine the structure of the data frame
str(BusStop)
```

There are now a total of 5160 observations, after removing the duplicated record. However, further checks in the code chunk below shows that there should only be 5145 unique bus stop codes.

```{r}
n_distinct(BusStop$BUS_STOP_N)
```
The code chunk below shows a list of duplicated bus stop codes. Based on the output below, there are 15 bus stops with duplicated records. 

```{r}
duplicate <- BusStop %>%
  group_by(BUS_STOP_N) %>%
  filter(n() > 1) %>%
  arrange(BUS_STOP_N)

kable(duplicate)
```

The code chunk below uses the `distinct()` function to keep only the unique rows based on the `BUS_STOP_N` while preserving all other fields (`.keep_all = TRUE`). By default, `distinct()` keeps the first occurrence of each unique combination of values in the specified columns.

```{r}
BusStop <- BusStop %>%
  distinct(BUS_STOP_N, .keep_all = TRUE)

# Re-examine the structure of the data frame
str(BusStop)
```

There are now a total of 5145 observations, after removing the 15 duplicated bus stop codes. 

## Import Passenger Volume by Origin-Destination Bus Stops

The code chunk below uses the `read_csv()` function of `readr` package (imported with the `tidyverse` package) to import the csv files into R.

```{r}
odbus <- read_csv("data/aspatial/origin_destination_bus_202308.csv")

# Examine the structure of the data frame
str(odbus)
```

Based on the data frame structure seen above, `ORIGIN_PT_CODE` and `DESTINATION_PT_CODE` are listed as character variables. These variables are equivalent to `BUS_STOP_N` of `BusStop` sf data frame and should be transformed to factors so that R treats them as grouping variables.

```{r}
# Columns to convert to factors
columns_to_convert <- c("ORIGIN_PT_CODE", "DESTINATION_PT_CODE")

# Apply as.factor() to the adjusted columns
odbus[columns_to_convert] <- lapply(odbus[columns_to_convert], as.factor)

# Re-examine the structure of the data frame
str(odbus)
```

Based on the output above, `ORIGIN_PT_CODE` and `DESTINATION_PT_CODE` are now factors.

## Extract Commuting Flow data

The code chunk below extracts commuting flows for the four target time periods. For completeness, a list of all possible Bus Stops x Day Time x Time combinations is created. Following which, the commuting flow for each Bus Stops x Day Time x Time combination within the `odbus` data frame is computed and missing combinations are imputed with a value of 0. Lastly the resultant data frame is pivoted wider to form a data frame where each row represents one bus stop code, similar to the BusStop sf data frame. 

```{r}
# Create a list of possible bus stop code, day type and time per hour for checking
BusStopList <- expand.grid(ORIGIN_PT_CODE = unique(BusStop$BUS_STOP_N),
                          DAY_TYPE = c("WEEKDAY", "WEEKENDS/HOLIDAY"),
                          TIME_PER_HOUR = unique(odbus$TIME_PER_HOUR))

# Commute commuting flow by bus stop code, day type and time per hour
odbus_recoded <- odbus %>%
  group_by(ORIGIN_PT_CODE, DAY_TYPE, TIME_PER_HOUR) %>%
  summarise(TRIPS = sum(TOTAL_TRIPS)) 

# Identify missing Bus Stops and impute a 0 value
odbus_missing <- BusStopList %>%
  anti_join(odbus_recoded, by = c("ORIGIN_PT_CODE", "DAY_TYPE", "TIME_PER_HOUR")) %>%
  mutate(TRIPS = 0)

# Combine the above two data frames
odbus_long <- rbind(odbus_recoded, odbus_missing) %>%
    mutate(peak_period = case_when(
    DAY_TYPE == "WEEKDAY" & TIME_PER_HOUR >= 6 & TIME_PER_HOUR <=9 ~ 
      "weekday_morn",
    DAY_TYPE == "WEEKDAY" & TIME_PER_HOUR >= 17 & TIME_PER_HOUR <=20 ~ 
      "weekday_evening",
    DAY_TYPE == "WEEKENDS/HOLIDAY" & TIME_PER_HOUR >= 11 & TIME_PER_HOUR <=14 ~ 
      "weekend_morn",
    DAY_TYPE == "WEEKENDS/HOLIDAY" & TIME_PER_HOUR >= 16 & TIME_PER_HOUR <=19 ~ 
      "weekend_evening",
    TRUE ~ "non_peak")) 

# Pivot wider to form data frame with one bus stop code per row
odbus_wide_peak <- odbus_long %>%
  group_by(ORIGIN_PT_CODE, peak_period) %>%
  summarise(TOTAL_TRIPS = sum(TRIPS)) %>%
  pivot_wider(names_from = peak_period,
              values_from = TOTAL_TRIPS)

odbus_wide <- odbus_long %>%
  filter(!(peak_period == "non_peak")) %>%
  group_by(ORIGIN_PT_CODE, DAY_TYPE, TIME_PER_HOUR) %>%
  summarise(TOTAL_TRIPS = sum(TRIPS)) %>%
  mutate(Day_Time = paste(DAY_TYPE, TIME_PER_HOUR)) %>%
  ungroup %>%
  select(-c(DAY_TYPE, TIME_PER_HOUR)) %>%
  pivot_wider(names_from = Day_Time,
              values_from = TOTAL_TRIPS) %>%
  left_join(odbus_wide_peak)
```

## Append Commuting Flow data with Bus Stop Locations

`left_join()` of **dplyr** is then used to join the geographical data and commuting flow data table using the Bus Stop Code as the common identifier. Left join is done to ensure that the geospatial properties (geometry column) of the `BusStop` sf data frame is retained and bus stops not found within the geospatial data set are dropped.

```{r}
odBusStop <- left_join(BusStop, odbus_wide, by = c("BUS_STOP_N" = "ORIGIN_PT_CODE"))

str(odBusStop)
```

There are a total of 5145 observations, which matches the number of features in the `BusStop` sf data frame.

# Geovisualisation and Analysis

## Create Spatial Grids

Spatial grids are commonly used in spatial analysis to divide the study area into equal-sized, regular polygons that can tessellate the whole study area. After that, a variable is summarized within each polygon. For this exercise, a hexagon layer of 250m (where 250m is the perpendicular distance between the hexagon centre and its edges) will be created.

In the code chunk below, `st_make_grid` is used to create the hexagon grids using the `svy21` projected coordinate system. In `st_make_grid`, `cellsize` argument refers to the cell size in the units that the crs of the spatial data is using. The cellsize can be defined as the distance between opposite edges. Since the data is set in SVY21 projected coordinate system, which [uses metres as the unit](https://epsg.io/3414), the value is set as `c(500,500)` to create a hexagon layer of 250m. The resulting data frame is then converted into a sf data frame and an index is added for each hexagon grid. 

```{r}
hex_grid <- st_make_grid(odBusStop, cellsize = c(500, 500), 
                         crs = 3413, what = "polygons", square = FALSE) %>%
  st_sf() %>%
  mutate(index = row_number())
```

In the code chunk below, `st_join` and `st_intersects()` is used to return a list of bus stops lying within each hexagon grid. A left join is done in this process (using the argument `left = TRUE`) to ensure that the geospatial properties (geometry column) of the `hex_grid` sf data frame is retained. After filtering out hexagon grids that do not contain any bus stops, the number of bus stops and the total number of trips at each time period is then computed for each hexagon grid. 

```{r}
hex_grid_count <- st_join(hex_grid, odBusStop, join = st_intersects, left = TRUE) %>%
  filter(!(is.na(BUS_STOP_N))) %>%
  group_by(index) %>%
  summarise(
    count = n(),
    bus_stop_codes = paste(BUS_STOP_N, collapse = ", "),
    bus_stop_names = paste(LOC_DESC, collapse = ", "),
    across(starts_with("week"), sum)
  ) %>%
  ungroup()
```

The `hex_grid_count` sf data frame can now be used for plotting the geographical distribution of peak hour bus stops and commuting flow using **tmap**.

Before moving on to the data visualisation, save `hex_grid` and `hex_grid_count` sf data frames into rds file format. 

```{r}
write_rds(hex_grid, "data/rds/hex_grid.rds")
write_rds(hex_grid_count, "data/rds/hex_grid_count.rds")
```

## Visualisation of Geographical Distribution of Commuting Flow

For efficiency of plotting, select just the columns that will be used for this section.

```{r}
hex_grid_count2 <- hex_grid_count %>%
  select(index, count, bus_stop_codes, bus_stop_names, geometry,
         weekday_evening, weekday_morn, weekend_evening, weekend_morn)
```

### Continuous Scale

Plotting the geographical distribution of the weekdays and weekends peak hour commuting flows side by side shows a heavily right-skewed distribution across all four target time periods i.e. most bus stops have less than 100k commuter trips at each of these time periods. 

```{r, fig.height=12, fig.width=15}
tmap_mode("view")

tm_shape(hex_grid_count2) +
  tm_fill(col = c("weekday_morn", "weekday_evening", 
                  "weekend_morn", "weekend_evening"),
          palette = "Blues",
          style = "cont",
          popup.vars = c("Bus Stops" = "bus_stop_codes", 
                         "Weekday Morning" = "weekday_morn", 
                         "Weekday Evening" = "weekday_evening",
                         "Weekend/PH Morning" = "weekend_morn", 
                         "Weekend/PH Evening" = "weekend_evening")) + 
  tm_layout(title = c("Weekday Morning", "Weekday Evening",
                      "Weekend/PH Morning", "Weekend/PH Evening")) +
  tm_facets(nrow = 4, free.scales = FALSE)
```

### Jenks Natural Breaks

The Jenks optimization method, also called the Jenks natural breaks classification method, is a data clustering method designed to determine the best arrangement of values into different classes. This is done by seeking to minimize each class's average deviation from the class mean, while maximizing each class's deviation from the means of the other classes. In other words, the method seeks to reduce the variance within classes and maximize the variance between classes. `n=6` is used for this exercise.

```{r, fig.height=12, fig.width=15}
tmap_mode("view")

tm_shape(hex_grid_count2) +
  tm_fill(col = c("weekday_morn", "weekday_evening", 
                  "weekend_morn", "weekend_evening"),
          palette = "Blues",
          n = 6, style = "jenks",
          popup.vars = c("Bus Stops" = "bus_stop_codes", 
                         "Weekday Morning" = "weekday_morn", 
                         "Weekday Evening" = "weekday_evening",
                         "Weekend/PH Morning" = "weekend_morn", 
                         "Weekend/PH Evening" = "weekend_evening")) + 
  tm_layout(title = c("Weekday Morning", "Weekday Evening",
                      "Weekend/PH Morning", "Weekend/PH Evening")) +
  tm_facets(nrow = 4, free.scales = FALSE)
```


# Emerging Hot Spot Analysis

Continue to Emerging Hot Spot Analysis [here](https://geospatial2023.netlify.app/take_home_exercise/ex1/take_home_ex1b). 
